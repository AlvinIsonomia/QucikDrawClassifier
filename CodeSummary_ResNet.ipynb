{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt # 基础数据处理\n",
    "\n",
    "from random import sample # 随机采样\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader # Pytorch\n",
    "print(torch.__version__)\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from tqdm import tqdm as tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset & Dataloader & Preprocessing\n",
    "For dataprocessing, the mean and std will be computed when init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 2469/10804 [00:00<00:00, 24685.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading class: airplane in ./train\n",
      "loading class: ant in ./train\n",
      "loading class: bear in ./train\n",
      "loading class: bird in ./train\n",
      "loading class: bridge in ./train\n",
      "loading class: bus in ./train\n",
      "loading class: calendar in ./train\n",
      "loading class: car in ./train\n",
      "loading class: chair in ./train\n",
      "loading class: dog in ./train\n",
      "loading class: dolphin in ./train\n",
      "loading class: door in ./train\n",
      "loading class: flower in ./train\n",
      "loading class: fork in ./train\n",
      "loading class: truck in ./train\n",
      "loading class: airplane in ./extra_training_data/data\n",
      "loading class: ant in ./extra_training_data/data\n",
      "loading class: bear in ./extra_training_data/data\n",
      "loading class: bird in ./extra_training_data/data\n",
      "loading class: bridge in ./extra_training_data/data\n",
      "loading class: bus in ./extra_training_data/data\n",
      "loading class: calendar in ./extra_training_data/data\n",
      "loading class: car in ./extra_training_data/data\n",
      "loading class: chair in ./extra_training_data/data\n",
      "loading class: dog in ./extra_training_data/data\n",
      "loading class: dolphin in ./extra_training_data/data\n",
      "loading class: door in ./extra_training_data/data\n",
      "loading class: flower in ./extra_training_data/data\n",
      "loading class: fork in ./extra_training_data/data\n",
      "loading class: truck in ./extra_training_data/data\n",
      "Data loading finished, 10804 totally\n",
      "Data Cleaning Fire ON!!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10804/10804 [00:00<00:00, 11162.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loading finished, 10370 remaining\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_root = './train'\n",
    "labels = os.listdir(train_root)\n",
    "\n",
    "\n",
    "class DrawDataset(Dataset):\n",
    "    def __init__(self, data_root = '',transform = None,anlysis = False):\n",
    "        self.mean = 0.16443629118313927\n",
    "        self.std = 0.3239202530511322\n",
    "        self.transform = transform\n",
    "        self.anlysis = False # only used when first computation\n",
    "        self.label_mapper = {'airplane': 0, 'ant': 1, 'bear': 2, 'bird': 3, 'bridge': 4,\n",
    "                        'bus'     : 5, 'calendar': 6, 'car': 7, 'chair': 8, 'dog': 9,\n",
    "                        'dolphin' : 10, 'door': 11, 'flower': 12, 'fork': 13, 'truck': 14}\n",
    "        self.IO_mapper = []\n",
    "        for train_root in data_root:\n",
    "            for x in self.label_mapper:\n",
    "                print('loading class:',x,'in',train_root)\n",
    "                temp_root = os.path.join(train_root,x)\n",
    "                temp_list = os.listdir(temp_root)\n",
    "                for img in temp_list:\n",
    "                    full_str = os.path.join(temp_root,img)\n",
    "                    self.IO_mapper.append([full_str , self.label_mapper[x]])\n",
    "        print('Data loading finished,',len(self.IO_mapper),'totally')\n",
    "        print('Data Cleaning Fire ON!!!')\n",
    "        self.CleanIO_mapper = []\n",
    "        for i in tqdm(range(0,len(self.IO_mapper))):\n",
    "            figure = cv2.imread(self.IO_mapper[i][0],0)\n",
    "            try:\n",
    "                shape = figure.shape\n",
    "            except:\n",
    "#                 print('Oh, you can not really drawing~')\n",
    "                continue\n",
    "            else:\n",
    "                if figure.shape != (28,28):\n",
    "                    continue\n",
    "                else:\n",
    "                    self.CleanIO_mapper.append(self.IO_mapper[i])\n",
    "#                     print('Oh, you can really drawing~')\n",
    "        self.IO_mapper = self.CleanIO_mapper\n",
    "        del self.CleanIO_mapper\n",
    "        print('Data loading finished,',len(self.IO_mapper),'remaining')\n",
    "        if anlysis:\n",
    "            self.analysis()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.IO_mapper)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        image = cv2.imread(self.IO_mapper[idx][0],0)\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(Image.fromarray(image))\n",
    "        return image,self.IO_mapper[idx][1]\n",
    "    \n",
    "    def analysis(self):\n",
    "        print('Data analysising……')\n",
    "        self.mean = 0\n",
    "        self.std = 0\n",
    "        temp = []\n",
    "        for i in tqdm(self):\n",
    "            img = i[0].flatten() # 转为一维数组方便计算\n",
    "            self.mean += np.sum(img)\n",
    "        self.mean = self.mean / (len(self)*img.size)\n",
    "        print('Mean:',self.mean)\n",
    "        for i in self:\n",
    "            img = i[0].flatten() # 转为一维数组方便计算\n",
    "            self.std = self.std + np.sum((img - self.mean) ** 2)\n",
    "        self.std = np.sqrt(self.std / (len(self)*img.size))\n",
    "        print('Std:',self.std)\n",
    "\n",
    "\n",
    "# Preprocessing\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomCrop(28,padding = 4), # 在周围补0后随机裁切，相当于平移这个图像\n",
    "#     transforms.Resize(32),\n",
    "    transforms.RandomHorizontalFlip(), # 一半的概率水平翻转\n",
    "    transforms.RandomRotation((-15,15)), # 随机旋转\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.16443629118313927, ),(0.3239202530511322, ))\n",
    "])\n",
    "\n",
    "# Dataset & Dataloader\n",
    "Draws = DrawDataset(['./train','./extra_training_data/data'],transform = train_transform)\n",
    "dl = DataLoader(Draws, batch_size = 4, shuffle = True, num_workers = 8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28)\n"
     ]
    }
   ],
   "source": [
    "a = cv2.imread(Draws.IO_mapper[0][0],0).shape\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show Images & Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chair bear airplane door \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def imshow(img):\n",
    "    img = img/2 + 0.5 # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg,(1,2,0)))\n",
    "\n",
    "dataiter = iter(dl)\n",
    "images,labels = dataiter.next()\n",
    "\n",
    "k = list(Draws.label_mapper.keys()) # [1,2,3,5,4]\n",
    "v = list(Draws.label_mapper.values()) #[3,5,2,1,1]\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "\n",
    "labelshow = ''\n",
    "for i in labels:\n",
    "    labelshow += k[v.index(i)] + ' '\n",
    "print(labelshow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We will implement this model on: cuda !\n",
      "Image batch dimensions: torch.Size([512, 1, 28, 28])\n",
      "Image label dimensions: torch.Size([512])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# Hyperparameters\n",
    "RANDOM_SEED = 1\n",
    "LEARNING_RATE = 0.0005\n",
    "WEIGHT_DECAY = 0.001\n",
    "BATCH_SIZE = 512\n",
    "NUM_EPOCHS = 750\n",
    "\n",
    "# Architecture\n",
    "NUM_FEATURES = 28*28\n",
    "NUM_CLASSES = 15\n",
    "\n",
    "# Other\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "GRAYSCALE = True\n",
    "print('We will implement this model on:',DEVICE,'!')\n",
    "\n",
    "# for server-1\n",
    "# Datasets\n",
    "trainset = Draws\n",
    "\n",
    "# DataLoader\n",
    "\n",
    "trainloader = DataLoader(Draws, batch_size=BATCH_SIZE, shuffle = True, num_workers = 0)\n",
    "\n",
    "classes = ['airplane', 'ant', 'bear', 'bird', 'bridge',\n",
    "                        'bus', 'calendar', 'car', 'chair', 'dog',\n",
    "                        'dolphin', 'door', 'flower', 'fork', 'truck']\n",
    "\n",
    "# Checking datasets\n",
    "for images, labels in trainloader:  \n",
    "    print('Image batch dimensions:', images.shape)\n",
    "    print('Image label dimensions:', labels.shape)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "    \n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, num_classes, grayscale):\n",
    "        self.inplanes = 64\n",
    "        in_dim = 1\n",
    "        super(ResNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_dim, 64, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "        self.avgpool = nn.AvgPool2d(7, stride=1)\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, (2. / n)**.5)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        # because MNIST is already 1x1 here:\n",
    "        # disable avg pooling\n",
    "        #x = self.avgpool(x)\n",
    "        \n",
    "        x = x.view(x.size(0), -1)\n",
    "        logits = self.fc(x)\n",
    "        probas = F.softmax(logits, dim=1)\n",
    "        return logits, probas\n",
    "\n",
    "\n",
    "\n",
    "def resnet34(num_classes):\n",
    "    \"\"\"Constructs a ResNet-34 model.\"\"\"\n",
    "    model = ResNet(block=BasicBlock, \n",
    "                   layers=[3, 4, 6, 3],\n",
    "                   num_classes=NUM_CLASSES,\n",
    "                   grayscale=GRAYSCALE)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "model = resnet34(NUM_CLASSES)\n",
    "model.to(DEVICE)\n",
    "if(DEVICE == 'cuda'):\n",
    "    model=torch.nn.DataParallel(model)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size 16 3 3 3, expected input[128, 1, 28, 28] to have 3 channels, but got 1 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-944b691aa6dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m### FORWARD AND BACK PROP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0mcost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    150\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0mreplicas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(self, replicas, inputs, kwargs)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/torch/nn/parallel/parallel_apply.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(modules, inputs, kwargs_tup, devices)\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/torch/nn/parallel/parallel_apply.py\u001b[0m in \u001b[0;36m_worker\u001b[0;34m(i, module, input, kwargs, device)\u001b[0m\n\u001b[1;32m     57\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m                 \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-cb83ac1fb226>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    336\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    337\u001b[0m         return F.conv2d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 338\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size 16 3 3 3, expected input[128, 1, 28, 28] to have 3 channels, but got 1 channels instead"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch.nn.functional as F\n",
    "def compute_accuracy(model, data_loader, device):\n",
    "    correct_pred, num_examples = 0, 0\n",
    "    for i, (features, targets) in enumerate(data_loader):\n",
    "            \n",
    "        features = features.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        logits, probas = model(features)\n",
    "        _, predicted_labels = torch.max(probas, 1)\n",
    "        num_examples += targets.size(0)\n",
    "        correct_pred += (predicted_labels == targets).sum()\n",
    "    return correct_pred.float()/num_examples * 100\n",
    "    \n",
    "\n",
    "start_time = time.time()\n",
    "for epoch in range(0, NUM_EPOCHS):\n",
    "    \n",
    "    model.train()\n",
    "    for batch_idx, (features, targets) in enumerate(trainloader):\n",
    "        \n",
    "        features = features.to(DEVICE)\n",
    "        targets = targets.to(DEVICE)\n",
    "            \n",
    "        ### FORWARD AND BACK PROP\n",
    "        logits, probas = model(features)\n",
    "        cost = F.cross_entropy(logits, targets)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        cost.backward()\n",
    "        \n",
    "        ### UPDATE MODEL PARAMETERS\n",
    "        optimizer.step()\n",
    "        \n",
    "        ### LOGGING\n",
    "        if not batch_idx % 70:\n",
    "            print ('Epoch: %03d/%03d | Batch %04d/%04d | Cost: %.4f' \n",
    "                   %(epoch+1, NUM_EPOCHS, batch_idx, \n",
    "                     len(trainloader), cost))\n",
    "\n",
    "        \n",
    "\n",
    "    model.eval()\n",
    "    with torch.set_grad_enabled(False): # save memory during inference\n",
    "        print('Epoch: %03d/%03d | Train: %.3f%%' % (\n",
    "              epoch+1, NUM_EPOCHS, \n",
    "              compute_accuracy(model, trainloader, device=DEVICE)))\n",
    "        \n",
    "    print('Time elapsed: %.2f min' % ((time.time() - start_time)/60))\n",
    "    \n",
    "print('Total Training Time: %.2f min' % ((time.time() - start_time)/60))\n",
    "\n",
    "\n",
    "with torch.set_grad_enabled(False): # save memory during inference\n",
    "    print('Test accuracy: %.2f%%' % (compute_accuracy(model, trainloader, device=DEVICE)))\n",
    "    \n",
    "print('Total Time: %.2f min' % ((time.time() - start_time)/60))\n",
    "\n",
    "\n",
    "\n",
    "def save_model(the_model, PATH = 'final.pkl'):\n",
    "    torch.save(the_model.module.state_dict(), PATH)\n",
    "\n",
    "\n",
    "    \n",
    "save_model(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(the_model, PATH = 'final.pkl'):\n",
    "    torch.save(the_model.module.state_dict(), PATH)\n",
    "\n",
    "\n",
    "    \n",
    "save_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference\n",
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): ResNet(\n",
       "    (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (4): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (5): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
       "    (fc): Linear(in_features=512, out_features=15, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model_loader\n",
    "\n",
    "\n",
    "\n",
    "def load_model(PATH = 'final.pkl'):\n",
    "    test_model = resnet34(NUM_CLASSES)\n",
    "    test_model.load_state_dict(torch.load(PATH))\n",
    "    return test_model\n",
    "\n",
    "\n",
    "test_model = load_model()\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "test_model.to(DEVICE)\n",
    "if(DEVICE == 'cuda'):\n",
    "    test_model=torch.nn.DataParallel(test_model)\n",
    "\n",
    "test_model.eval()\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TestDataSet & DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loading finished, 45000 totally\n"
     ]
    }
   ],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, data_root = '',transform = None):\n",
    "        self.mean = 0.16443629118313927\n",
    "        self.std = 0.3239202530511322\n",
    "        self.transform = transform\n",
    "        self.label_mapper = {'airplane': 0, 'ant': 1, 'bear': 2, 'bird': 3, 'bridge': 4,\n",
    "                        'bus'     : 5, 'calendar': 6, 'car': 7, 'chair': 8, 'dog': 9,\n",
    "                        'dolphin' : 10, 'door': 11, 'flower': 12, 'fork': 13, 'truck': 14}\n",
    "        self.IO_mapper = []\n",
    "        self.picids = []\n",
    "        temp_list = os.listdir(data_root)\n",
    "        for img in temp_list:\n",
    "            self.picids.append(img.split('.')[0])\n",
    "            full_str = os.path.join(data_root,img)\n",
    "            self.IO_mapper.append(full_str)\n",
    "        print('Data loading finished,',len(self.IO_mapper),'totally')\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.IO_mapper)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        image = cv2.imread(self.IO_mapper[idx],0)\n",
    "        picid = self.picids[idx]\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(Image.fromarray(image))\n",
    "        return picid, image\n",
    "\n",
    "# Preprocessing\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.16443629118313927, ),(0.3239202530511322, ))\n",
    "])\n",
    "test_root = './released_test'\n",
    "# Dataset & Dataloader\n",
    "TestD = TestDataset(test_root, transform = test_transform)\n",
    "Testdl = DataLoader(TestD, batch_size = 1024, shuffle = True, num_workers = 8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do inference & writing csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "33it [00:03, 12.98it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-72eccf90569d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpicids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTestdl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mpicids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpicids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "import time\n",
    "import torch.nn.functional as F\n",
    "def compute_accuracy(model, data_loader, device):\n",
    "    correct_pred, num_examples = 0, 0\n",
    "    for i, (features, targets) in enumerate(data_loader):\n",
    "            \n",
    "        features = features.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        logits, probas = model(features)\n",
    "        _, predicted_labels = torch.max(probas, 1)\n",
    "        num_examples += targets.size(0)\n",
    "        correct_pred += (predicted_labels == targets).sum()\n",
    "    return correct_pred.float()/num_examples * 100\n",
    "    \n",
    "\n",
    "start_time = time.time()\n",
    "pics = []\n",
    "labels = []\n",
    "with torch.set_grad_enabled(False): \n",
    "    for i, (picids,features) in tqdm(enumerate(Testdl)):\n",
    "        features = features.to(DEVICE)\n",
    "        picids = list(picids)\n",
    "        logits, probas = test_model(features)\n",
    "        _, predicted_labels = torch.max(probas, 1)\n",
    "        predicted_labels = list(predicted_labels.cpu().numpy())\n",
    "        pics += picids\n",
    "        labels += predicted_labels\n",
    "    print(len(pics),len(labels))\n",
    "    \n",
    "headers = ['id','categories']\n",
    "\n",
    "with open('019033910029.csv','w')as f:\n",
    "    f_csv = csv.writer(f)\n",
    "    f_csv.writerow(headers)\n",
    "    for i in tqdm(range(0,len(pics))):\n",
    "        f_csv.writerow([int(pics[i]),int(labels[i])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
